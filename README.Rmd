---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# ytdlpr

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->

ytdlpr wraps some functionalities of `yt-dlp` to facilitate their use in R-based workflows. It is currently focused on retrieving and parsing subtitles.

## Installation

You can install the development version of `ytdlpr` from [GitHub](https://github.com/giocomai/ytdlpr) with:

``` r
remotes::install_github("giocomai/ytdlpr")
```

## Documentation 

Let's say we want to retrieve some information about [this playlist](https://www.youtube.com/playlist?list=PLbyvawxScNbtMcDKmT2dRAfjmSFwOt1Vj) of video files published by the European Space Agency (chosen at random). The reference use case is about retrieving subtitles, but documentation about other use cases will be added. 

We will first need to set a base folder where all the files retrieved with this package will be stored. I like to store such things under the R folder of my home directory, so I may proceed as follows:

```{r set_base_folder}
library("ytdlpr")

yt_set_base_folder(path = fs::path(
  fs::path_home_r(),
  "R",
  "ytdlpr" # you'd probably set something meaningful here, relevant to what you're downloading
))
```

Throughout the current session, this will be the main folder where I'll be storing files. If not set, it will default to storing things inside the current working directory. 

What happens next depends a bit on your starting point, i.e., if you have a set of urls of individual videos or if you want to retrieve subtitles about a whole playlist. 

### Retrieve subtitles starting from single video urls/id


### Retrieve subtitles starting from a playlist

A first step, that if not explicitly done will be performed implicitly by other playlist-based functions is to retrieve all identifiers from the given playlist.

```{r yt_get_playlist_id}
yt_get_playlist_id(
  playlist = "https://www.youtube.com/playlist?list=PLbyvawxScNbuSi7sJaJbHNyyx3iYJeW3P"
)
```
Notice that the data are stored locally: unless the `update` argument in `yt_get_playlist_id()` is set to TRUE, following calls to this function will just retrieve locally stored identifiers.

If all we really care about is subtitles, we can skip this step and move on to downloading subtitles. By default, this will proceed with downloading English language subtitles, but you can customise this using the dedicated function.

```{r yt_get_subtitles_playlist, eval = FALSE}
yt_get_subtitles_playlist(
  playlist = "https://www.youtube.com/playlist?list=PLbyvawxScNbuSi7sJaJbHNyyx3iYJeW3P"
)
```

This will download all relevant subtitles and return a data frame with some basic metadata about them.

The next step is to actually import these subtitles in a format that is easy to parse in R. You can download and import them in a single go with:

```{r yt_get_subtitles_playlist and yt_read_vtt}
yt_get_subtitles_playlist(
  playlist = "https://www.youtube.com/playlist?list=PLbyvawxScNbuSi7sJaJbHNyyx3iYJeW3P"
) |>
  yt_read_vtt()
```

Or, yf you want to parse only subtitles that are locally available, you can achieve the same with `yt_get_local_subtitles()`: 

```{r yt_get_local_subtitles and yt_read_vtt}
subs_df <- yt_get_local_subtitles(
  playlist = "https://www.youtube.com/playlist?list=PLbyvawxScNbuSi7sJaJbHNyyx3iYJeW3P"
) |>
  yt_read_vtt()
```



